# ðŸ¤– Feature 3: AI-Ready Content Structure Analyzer - Technical Specification

**Feature**: AI-Ready Content Structure Analysis  
**Version**: 1.0  
**Date**: January 8, 2025  
**Status**: Ready for Implementation  
**Implementation Priority**: High  

---

## ðŸ“‹ Feature Overview

### **Purpose**
The AI-Ready Content Structure Analyzer is a sophisticated content evaluation system that analyzes web content for AI crawler optimization, featured snippet readiness, and search engine visibility. This feature serves as a "content linter" that provides actionable recommendations for optimizing content structure specifically for AI-driven search algorithms.

### **Business Value**
- **Content Optimization**: Systematic approach to improving content for AI crawlers and featured snippets
- **Competitive Analysis**: Understanding how top-ranking content is structured for AI consumption
- **Quality Assurance**: Automated content auditing with scoring and recommendations
- **SEO Enhancement**: Specific optimizations for voice search, featured snippets, and AI-powered results

### **Target Users**
- Content marketers optimizing for AI-driven search
- SEO professionals auditing content structure
- Content writers seeking structured feedback
- Agencies providing content optimization services

---

## ðŸŽ¯ Functional Requirements

### **Core Functionality**
- **FR-301**: Analyze HTML content structure and hierarchy
- **FR-302**: Evaluate readability metrics for AI consumption
- **FR-303**: Score structured data implementation and schema.org markup
- **FR-304**: Assess featured snippet optimization potential
- **FR-305**: Generate actionable improvement recommendations
- **FR-306**: Support both URL-based and direct content analysis

### **Analysis Components**
- **FR-307**: Header hierarchy validation (H1-H6 structure)
- **FR-308**: Content organization scoring (lists, tables, sections)
- **FR-309**: Reading difficulty assessment using multiple algorithms
- **FR-310**: AI-friendly formatting evaluation (short paragraphs, bullet points)
- **FR-311**: Question-answer pattern detection for featured snippets
- **FR-312**: Schema.org structured data validation

### **Output & Reporting**
- **FR-313**: Overall AI-readiness score (0-100)
- **FR-314**: Component-specific scoring with explanations
- **FR-315**: Prioritized improvement recommendations
- **FR-316**: Before/after comparison for content optimization
- **FR-317**: Export capabilities for reporting and integration

---

## ðŸ—ï¸ Technical Architecture

### **Service Architecture**
```python
class AIContentStructureAnalyzerService:
    """
    AI-Ready Content Structure Analysis Service
    
    Analyzes content structure for AI crawler optimization, featured snippet
    readiness, and search engine visibility enhancement.
    """
    
    def __init__(self, config: AnalyzerConfig):
        self.config = config
        self.html_parser = HTMLStructureParser()
        self.readability_analyzer = ReadabilityAnalyzer()
        self.schema_validator = SchemaValidator()
        self.ai_optimizer = AIOptimizationAnalyzer()
        self.cache_service = CacheService()
        
    async def analyze_content_structure(self, 
                                      content: str = None,
                                      url: str = None,
                                      user_id: str = None,
                                      options: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """
        Main analysis method for content structure evaluation
        
        Args:
            content: Raw HTML content to analyze
            url: URL to fetch and analyze content from
            user_id: User performing the analysis
            options: Analysis configuration options
            
        Returns:
            Comprehensive structure analysis results
        """
```

### **Core Components**

#### **1. HTML Structure Parser**
```python
class HTMLStructureParser:
    """Parse and analyze HTML structure for AI optimization"""
    
    def parse_content(self, html_content: str) -> ParsedContent:
        """Extract structured data from HTML content"""
        
    def analyze_header_hierarchy(self, content: ParsedContent) -> HeaderAnalysis:
        """Validate H1-H6 hierarchy and structure"""
        
    def extract_content_elements(self, content: ParsedContent) -> ContentElements:
        """Identify lists, tables, sections, and other structural elements"""
        
    def detect_schema_markup(self, content: ParsedContent) -> SchemaData:
        """Extract and validate schema.org structured data"""
```

#### **2. Readability Analyzer**
```python
class ReadabilityAnalyzer:
    """Multi-algorithm readability assessment for AI consumption"""
    
    def calculate_readability_scores(self, text: str) -> ReadabilityScores:
        """Calculate Flesch-Kincaid, Gunning Fog, SMOG, and ARI scores"""
        
    def analyze_sentence_structure(self, text: str) -> SentenceAnalysis:
        """Evaluate sentence length, complexity, and AI-friendly formatting"""
        
    def assess_paragraph_structure(self, content: ParsedContent) -> ParagraphAnalysis:
        """Analyze paragraph length and organization for AI readability"""
```

#### **3. AI Optimization Analyzer**
```python
class AIOptimizationAnalyzer:
    """Evaluate content for AI crawler and featured snippet optimization"""
    
    def analyze_featured_snippet_potential(self, content: ParsedContent) -> SnippetAnalysis:
        """Assess content structure for featured snippet optimization"""
        
    def evaluate_question_answer_patterns(self, content: ParsedContent) -> QAAnalysis:
        """Detect and score question-answer formatting"""
        
    def assess_ai_crawler_optimization(self, content: ParsedContent) -> CrawlerAnalysis:
        """Evaluate content structure for AI crawler consumption"""
```

---

## ðŸ’¾ Database Design

### **Structure Analysis Model**
```python
from sqlalchemy import Column, String, Text, Float, DateTime, JSON
from sqlalchemy.ext.declarative import declarative_base
from datetime import datetime
import uuid

Base = declarative_base()

class StructureAnalysis(Base):
    """Database model for storing content structure analysis results"""
    
    __tablename__ = 'structure_analyses'
    
    id = Column(String(36), primary_key=True, default=lambda: str(uuid.uuid4()))
    url = Column(String(1000), nullable=True)  # Optional URL source
    content_hash = Column(String(64), nullable=False, index=True)  # Content fingerprint
    user_id = Column(String(36), nullable=False, index=True)
    
    # Core Analysis Results
    overall_score = Column(Float, nullable=False)  # 0-100 overall AI-readiness score
    header_score = Column(Float, nullable=False)   # Header hierarchy score
    readability_score = Column(Float, nullable=False)  # Readability score
    structure_score = Column(Float, nullable=False)    # Content structure score
    ai_optimization_score = Column(Float, nullable=False)  # AI optimization score
    
    # Detailed Analysis Data
    header_analysis = Column(JSON, nullable=False)      # Header structure details
    readability_metrics = Column(JSON, nullable=False)  # Readability calculations
    content_elements = Column(JSON, nullable=False)     # Lists, tables, sections
    schema_data = Column(JSON, nullable=True)           # Structured data found
    recommendations = Column(JSON, nullable=False)      # Improvement suggestions
    
    # Metadata
    analysis_options = Column(JSON, nullable=True)      # Configuration used
    processing_time = Column(Float, nullable=True)      # Analysis duration
    word_count = Column(Float, nullable=True)           # Content word count
    
    created_at = Column(DateTime, default=datetime.utcnow, index=True)
    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)
    
    def to_dict(self) -> Dict[str, Any]:
        """Convert analysis to dictionary for API responses"""
        return {
            'id': self.id,
            'url': self.url,
            'user_id': self.user_id,
            'overall_score': self.overall_score,
            'scores': {
                'header_score': self.header_score,
                'readability_score': self.readability_score,
                'structure_score': self.structure_score,
                'ai_optimization_score': self.ai_optimization_score
            },
            'analysis': {
                'header_analysis': self.header_analysis,
                'readability_metrics': self.readability_metrics,
                'content_elements': self.content_elements,
                'schema_data': self.schema_data
            },
            'recommendations': self.recommendations,
            'metadata': {
                'processing_time': self.processing_time,
                'word_count': self.word_count,
                'analysis_options': self.analysis_options
            },
            'created_at': self.created_at.isoformat(),
            'updated_at': self.updated_at.isoformat()
        }
```

### **Database Indexes**
```sql
-- Performance optimization indexes
CREATE INDEX idx_structure_user_created ON structure_analyses(user_id, created_at DESC);
CREATE INDEX idx_structure_hash ON structure_analyses(content_hash);
CREATE INDEX idx_structure_url ON structure_analyses(url);
CREATE INDEX idx_structure_score ON structure_analyses(overall_score DESC);
```

---

## ðŸ”Œ API Specification

### **Primary Endpoint**
```yaml
POST /api/content/structure-analysis
```

#### **Request Schema**
```json
{
  "content": "string (optional - HTML content to analyze)",
  "url": "string (optional - URL to fetch and analyze)",
  "options": {
    "include_readability": true,
    "include_schema_validation": true,
    "include_ai_optimization": true,
    "analysis_depth": "standard|deep",
    "target_audience": "general|technical|academic",
    "featured_snippet_focus": true
  }
}
```

#### **Response Schema**
```json
{
  "analysis_id": "uuid",
  "url": "string|null",
  "overall_score": 85,
  "scores": {
    "header_score": 92,
    "readability_score": 78,
    "structure_score": 88,
    "ai_optimization_score": 82
  },
  "analysis": {
    "header_analysis": {
      "h1_count": 1,
      "h1_content": "Main Article Title",
      "hierarchy_valid": true,
      "missing_levels": [],
      "header_distribution": {
        "h1": 1, "h2": 4, "h3": 8, "h4": 2
      }
    },
    "readability_metrics": {
      "flesch_kincaid_grade": 8.5,
      "gunning_fog_index": 9.2,
      "smog_index": 10.1,
      "average_sentence_length": 16.2,
      "reading_difficulty": "moderate"
    },
    "content_elements": {
      "paragraph_count": 12,
      "list_count": 3,
      "table_count": 1,
      "image_count": 5,
      "average_paragraph_length": 45.8
    },
    "ai_optimization": {
      "featured_snippet_potential": "high",
      "question_answer_patterns": 4,
      "short_paragraph_ratio": 0.75,
      "list_usage_score": 88
    },
    "schema_data": {
      "article_schema": true,
      "breadcrumb_schema": true,
      "faq_schema": false,
      "howto_schema": false
    }
  },
  "recommendations": [
    {
      "category": "header_structure",
      "priority": "high",
      "description": "Add H2 headings to break up long content sections",
      "impact_score": 15,
      "implementation": "Add H2 tags every 300-400 words"
    },
    {
      "category": "featured_snippets",
      "priority": "medium", 
      "description": "Format key answers in numbered lists for better snippet potential",
      "impact_score": 12,
      "implementation": "Convert 2-3 key answers to numbered list format"
    }
  ],
  "metadata": {
    "processing_time": 2.34,
    "word_count": 1247,
    "analysis_timestamp": "2025-01-08T10:30:00Z",
    "cache_status": "miss"
  }
}
```

### **Supporting Endpoints**
```yaml
# Retrieve stored analysis
GET /api/content/structure-analysis/{analysis_id}

# List user's structure analyses
GET /api/content/structure-analyses
  ?page=1&limit=20&sort=created_at&order=desc

# Delete analysis
DELETE /api/content/structure-analysis/{analysis_id}

# Bulk analysis for multiple URLs
POST /api/content/structure-analysis/bulk
```

---

## ðŸ§  Implementation Details

### **Complete Service Implementation**
```python
import hashlib
import asyncio
import aiohttp
from typing import Dict, Any, Optional, List
from datetime import datetime
import logging
from bs4 import BeautifulSoup
import textstat
import re
from urllib.parse import urlparse, urljoin

logger = logging.getLogger(__name__)

class AIContentStructureAnalyzerService:
    """
    AI-Ready Content Structure Analysis Service
    
    Comprehensive content analysis for AI crawler optimization,
    featured snippet readiness, and search engine visibility.
    """
    
    def __init__(self, db_session, cache_service, websocket_service=None):
        self.db_session = db_session
        self.cache_service = cache_service
        self.websocket_service = websocket_service
        
        # Analysis components
        self.html_parser = HTMLStructureParser()
        self.readability_analyzer = ReadabilityAnalyzer()
        self.schema_validator = SchemaValidator()
        self.ai_optimizer = AIOptimizationAnalyzer()
        
        # Configuration
        self.max_content_length = 500000  # 500KB content limit
        self.analysis_timeout = 30  # seconds
        
    async def analyze_content_structure(self,
                                      content: str = None,
                                      url: str = None,
                                      user_id: str = None,
                                      options: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """
        Main analysis method for content structure evaluation
        
        Performs comprehensive analysis including:
        - Header hierarchy validation
        - Readability assessment
        - AI optimization scoring
        - Featured snippet potential
        - Structured data validation
        """
        start_time = datetime.utcnow()
        
        try:
            # Validate input
            if not content and not url:
                raise ValueError("Either content or url must be provided")
            
            if not user_id:
                raise ValueError("user_id is required")
            
            # Set default options
            analysis_options = {
                'include_readability': True,
                'include_schema_validation': True,
                'include_ai_optimization': True,
                'analysis_depth': 'standard',
                'target_audience': 'general',
                'featured_snippet_focus': True,
                **(options or {})
            }
            
            # Emit progress update
            await self._emit_progress(user_id, "Starting content structure analysis", 5)
            
            # Fetch content if URL provided
            if url and not content:
                content = await self._fetch_content_from_url(url)
                await self._emit_progress(user_id, "Content fetched successfully", 15)
            
            # Generate content hash for caching
            content_hash = hashlib.sha256(content.encode()).hexdigest()
            
            # Check cache first
            cache_key = f"structure_analysis:{content_hash}:{hash(str(analysis_options))}"
            cached_result = await self.cache_service.get(cache_key)
            
            if cached_result:
                logger.info(f"Structure analysis cache hit for hash: {content_hash[:8]}")
                return {**cached_result, 'cache_status': 'hit'}
            
            # Parse HTML content
            await self._emit_progress(user_id, "Parsing HTML structure", 25)
            parsed_content = self.html_parser.parse_content(content)
            
            # Perform header analysis
            await self._emit_progress(user_id, "Analyzing header hierarchy", 35)
            header_analysis = self.html_parser.analyze_header_hierarchy(parsed_content)
            header_score = self._calculate_header_score(header_analysis)
            
            # Readability analysis
            readability_score = 0
            readability_metrics = {}
            if analysis_options['include_readability']:
                await self._emit_progress(user_id, "Calculating readability metrics", 50)
                readability_metrics = self.readability_analyzer.calculate_readability_scores(
                    parsed_content.text_content
                )
                readability_score = self._calculate_readability_score(readability_metrics)
            
            # Content structure analysis
            await self._emit_progress(user_id, "Analyzing content structure", 65)
            content_elements = self.html_parser.extract_content_elements(parsed_content)
            structure_score = self._calculate_structure_score(content_elements, parsed_content)
            
            # AI optimization analysis
            ai_optimization_score = 0
            ai_analysis = {}
            if analysis_options['include_ai_optimization']:
                await self._emit_progress(user_id, "Evaluating AI optimization", 80)
                ai_analysis = self.ai_optimizer.analyze_ai_optimization(
                    parsed_content, content_elements, analysis_options
                )
                ai_optimization_score = self._calculate_ai_optimization_score(ai_analysis)
            
            # Schema validation
            schema_data = None
            if analysis_options['include_schema_validation']:
                await self._emit_progress(user_id, "Validating structured data", 90)
                schema_data = self.schema_validator.detect_and_validate_schema(parsed_content)
            
            # Calculate overall score
            overall_score = self._calculate_overall_score({
                'header_score': header_score,
                'readability_score': readability_score,
                'structure_score': structure_score,
                'ai_optimization_score': ai_optimization_score
            })
            
            # Generate recommendations
            recommendations = self._generate_recommendations({
                'header_analysis': header_analysis,
                'readability_metrics': readability_metrics,
                'content_elements': content_elements,
                'ai_analysis': ai_analysis,
                'schema_data': schema_data,
                'overall_score': overall_score
            })
            
            # Calculate processing time
            processing_time = (datetime.utcnow() - start_time).total_seconds()
            
            # Create analysis result
            analysis_result = {
                'url': url,
                'overall_score': round(overall_score, 1),
                'scores': {
                    'header_score': round(header_score, 1),
                    'readability_score': round(readability_score, 1),
                    'structure_score': round(structure_score, 1),
                    'ai_optimization_score': round(ai_optimization_score, 1)
                },
                'analysis': {
                    'header_analysis': header_analysis,
                    'readability_metrics': readability_metrics,
                    'content_elements': content_elements,
                    'ai_optimization': ai_analysis,
                    'schema_data': schema_data
                },
                'recommendations': recommendations,
                'metadata': {
                    'processing_time': round(processing_time, 2),
                    'word_count': len(parsed_content.text_content.split()),
                    'analysis_options': analysis_options,
                    'analysis_timestamp': datetime.utcnow().isoformat(),
                    'cache_status': 'miss'
                }
            }
            
            # Store in database
            structure_analysis = StructureAnalysis(
                url=url,
                content_hash=content_hash,
                user_id=user_id,
                overall_score=overall_score,
                header_score=header_score,
                readability_score=readability_score,
                structure_score=structure_score,
                ai_optimization_score=ai_optimization_score,
                header_analysis=header_analysis,
                readability_metrics=readability_metrics,
                content_elements=content_elements,
                schema_data=schema_data,
                recommendations=recommendations,
                analysis_options=analysis_options,
                processing_time=processing_time,
                word_count=len(parsed_content.text_content.split())
            )
            
            self.db_session.add(structure_analysis)
            self.db_session.commit()
            
            # Add analysis ID to result
            analysis_result['analysis_id'] = structure_analysis.id
            
            # Cache the result (24 hour TTL)
            await self.cache_service.set(cache_key, analysis_result, ttl=86400)
            
            # Emit completion
            await self._emit_progress(user_id, "Analysis completed", 100)
            
            logger.info(f"Structure analysis completed for user {user_id} in {processing_time:.2f}s")
            
            return analysis_result
            
        except Exception as e:
            logger.error(f"Structure analysis failed for user {user_id}: {str(e)}")
            await self._emit_progress(user_id, f"Analysis failed: {str(e)}", -1)
            raise e
    
    def _calculate_header_score(self, header_analysis: Dict[str, Any]) -> float:
        """Calculate header hierarchy score (0-100)"""
        score = 100.0
        
        # Penalize missing H1
        if header_analysis['h1_count'] == 0:
            score -= 30
        elif header_analysis['h1_count'] > 1:
            score -= 15  # Multiple H1s penalty
        
        # Penalize poor hierarchy
        if not header_analysis['hierarchy_valid']:
            score -= 20
        
        # Penalize missing header levels
        missing_penalty = len(header_analysis.get('missing_levels', [])) * 5
        score -= missing_penalty
        
        # Bonus for good header distribution
        distribution = header_analysis.get('header_distribution', {})
        if distribution.get('h2', 0) >= 2:
            score += 5
        
        return max(0, min(100, score))
    
    def _calculate_readability_score(self, readability_metrics: Dict[str, Any]) -> float:
        """Calculate readability score optimized for AI consumption (0-100)"""
        if not readability_metrics:
            return 0
        
        # Target: 8th-10th grade reading level for optimal AI processing
        grade_level = readability_metrics.get('flesch_kincaid_grade', 12)
        
        # Optimal range: 6-10 grade level
        if 6 <= grade_level <= 10:
            grade_score = 100
        elif grade_level < 6:
            grade_score = 80 + (grade_level - 4) * 10  # Slightly penalize too easy
        else:
            grade_score = max(0, 100 - (grade_level - 10) * 8)  # Penalize too complex
        
        # Sentence length bonus/penalty
        avg_sentence_length = readability_metrics.get('average_sentence_length', 20)
        if 12 <= avg_sentence_length <= 20:
            sentence_score = 100
        else:
            sentence_score = max(0, 100 - abs(avg_sentence_length - 16) * 3)
        
        # Combine scores
        final_score = (grade_score * 0.7) + (sentence_score * 0.3)
        return max(0, min(100, final_score))
    
    def _calculate_structure_score(self, content_elements: Dict[str, Any], 
                                 parsed_content: Any) -> float:
        """Calculate content structure score (0-100)"""
        score = 70.0  # Base score
        
        # Paragraph structure
        avg_paragraph_length = content_elements.get('average_paragraph_length', 100)
        if 30 <= avg_paragraph_length <= 80:  # Optimal for AI
            score += 15
        elif avg_paragraph_length > 120:
            score -= 10  # Too long for AI processing
        
        # List usage bonus
        if content_elements.get('list_count', 0) > 0:
            score += 10
        
        # Table usage bonus
        if content_elements.get('table_count', 0) > 0:
            score += 5
        
        # Image optimization
        if content_elements.get('image_count', 0) > 0:
            score += 5
        
        return max(0, min(100, score))
    
    def _calculate_ai_optimization_score(self, ai_analysis: Dict[str, Any]) -> float:
        """Calculate AI optimization score (0-100)"""
        if not ai_analysis:
            return 0
        
        score = 50.0  # Base score
        
        # Featured snippet potential
        snippet_potential = ai_analysis.get('featured_snippet_potential', 'low')
        if snippet_potential == 'high':
            score += 20
        elif snippet_potential == 'medium':
            score += 10
        
        # Question-answer patterns
        qa_patterns = ai_analysis.get('question_answer_patterns', 0)
        score += min(qa_patterns * 5, 15)  # Max 15 points
        
        # Short paragraph ratio
        short_para_ratio = ai_analysis.get('short_paragraph_ratio', 0)
        score += short_para_ratio * 15  # Max 15 points for 100% short paragraphs
        
        return max(0, min(100, score))
    
    def _calculate_overall_score(self, scores: Dict[str, float]) -> float:
        """Calculate weighted overall score"""
        weights = {
            'header_score': 0.25,
            'readability_score': 0.25,
            'structure_score': 0.25,
            'ai_optimization_score': 0.25
        }
        
        weighted_sum = sum(scores[key] * weights[key] for key in weights)
        return max(0, min(100, weighted_sum))
    
    def _generate_recommendations(self, analysis_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Generate prioritized improvement recommendations"""
        recommendations = []
        
        # Header recommendations
        header_analysis = analysis_data.get('header_analysis', {})
        if header_analysis.get('h1_count', 0) == 0:
            recommendations.append({
                'category': 'header_structure',
                'priority': 'high',
                'description': 'Add a single, descriptive H1 tag to the page',
                'impact_score': 25,
                'implementation': 'Add one H1 tag at the top of your main content'
            })
        
        if not header_analysis.get('hierarchy_valid', True):
            recommendations.append({
                'category': 'header_structure',
                'priority': 'medium',
                'description': 'Fix header hierarchy - ensure headers follow logical order',
                'impact_score': 15,
                'implementation': 'Review header structure and ensure H2 follows H1, H3 follows H2, etc.'
            })
        
        # Readability recommendations
        readability_metrics = analysis_data.get('readability_metrics', {})
        grade_level = readability_metrics.get('flesch_kincaid_grade', 0)
        if grade_level > 12:
            recommendations.append({
                'category': 'readability',
                'priority': 'medium',
                'description': 'Simplify language for better AI understanding',
                'impact_score': 12,
                'implementation': 'Use shorter sentences and simpler vocabulary'
            })
        
        # AI optimization recommendations
        ai_analysis = analysis_data.get('ai_analysis', {})
        if ai_analysis.get('question_answer_patterns', 0) < 2:
            recommendations.append({
                'category': 'ai_optimization',
                'priority': 'medium',
                'description': 'Add more question-answer patterns for featured snippets',
                'impact_score': 18,
                'implementation': 'Format key information as questions followed by direct answers'
            })
        
        # Sort by impact score (highest first)
        recommendations.sort(key=lambda x: x['impact_score'], reverse=True)
        
        return recommendations[:10]  # Return top 10 recommendations
    
    async def _fetch_content_from_url(self, url: str) -> str:
        """Fetch HTML content from URL with proper error handling"""
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(url, timeout=10) as response:
                    if response.status == 200:
                        content = await response.text()
                        if len(content) > self.max_content_length:
                            raise ValueError(f"Content too large: {len(content)} bytes")
                        return content
                    else:
                        raise ValueError(f"Failed to fetch URL: HTTP {response.status}")
        except Exception as e:
            raise ValueError(f"Error fetching content from URL: {str(e)}")
    
    async def _emit_progress(self, user_id: str, message: str, percentage: int):
        """Emit progress update via WebSocket"""
        if self.websocket_service:
            try:
                await self.websocket_service.emit_to_user(user_id, 'structure_analysis_progress', {
                    'message': message,
                    'percentage': percentage,
                    'timestamp': datetime.utcnow().isoformat()
                })
            except Exception as e:
                logger.warning(f"Failed to emit progress update: {str(e)}")


class HTMLStructureParser:
    """Parse and analyze HTML structure for AI optimization"""
    
    def parse_content(self, html_content: str):
        """Parse HTML and extract structured content"""
        soup = BeautifulSoup(html_content, 'html.parser')
        
        # Remove script and style elements
        for script in soup(["script", "style"]):
            script.decompose()
        
        # Extract text content
        text_content = soup.get_text()
        
        # Clean up text
        lines = (line.strip() for line in text_content.splitlines())
        chunks = (phrase.strip() for line in lines for phrase in line.split("  "))
        text_content = ' '.join(chunk for chunk in chunks if chunk)
        
        return ParsedContent(soup=soup, text_content=text_content, html=html_content)
    
    def analyze_header_hierarchy(self, content):
        """Analyze header hierarchy and structure"""
        soup = content.soup
        
        # Find all headers
        headers = soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6'])
        
        # Count headers by level
        header_counts = {'h1': 0, 'h2': 0, 'h3': 0, 'h4': 0, 'h5': 0, 'h6': 0}
        header_sequence = []
        
        for header in headers:
            tag_name = header.name.lower()
            header_counts[tag_name] += 1
            header_sequence.append({
                'level': int(tag_name[1]),
                'text': header.get_text().strip()[:100],  # First 100 chars
                'tag': tag_name
            })
        
        # Validate hierarchy
        hierarchy_valid = self._validate_header_hierarchy(header_sequence)
        
        # Find missing levels
        missing_levels = []
        if header_counts['h1'] > 0:
            for level in range(1, 7):
                h_tag = f'h{level}'
                if header_counts[h_tag] == 0 and any(header_counts[f'h{i}'] > 0 for i in range(level + 1, 7)):
                    missing_levels.append(level)
        
        return {
            'h1_count': header_counts['h1'],
            'h1_content': headers[0].get_text().strip() if headers and headers[0].name == 'h1' else None,
            'hierarchy_valid': hierarchy_valid,
            'missing_levels': missing_levels,
            'header_distribution': header_counts,
            'header_sequence': header_sequence
        }
    
    def extract_content_elements(self, content):
        """Extract and analyze content elements"""
        soup = content.soup
        text = content.text_content
        
        # Count elements
        paragraphs = soup.find_all('p')
        lists = soup.find_all(['ul', 'ol'])
        tables = soup.find_all('table')
        images = soup.find_all('img')
        
        # Calculate average paragraph length
        paragraph_lengths = [len(p.get_text().strip()) for p in paragraphs if p.get_text().strip()]
        avg_paragraph_length = sum(paragraph_lengths) / len(paragraph_lengths) if paragraph_lengths else 0
        
        return {
            'paragraph_count': len(paragraphs),
            'list_count': len(lists),
            'table_count': len(tables),
            'image_count': len(images),
            'average_paragraph_length': round(avg_paragraph_length, 1),
            'paragraph_lengths': paragraph_lengths,
            'total_word_count': len(text.split())
        }
    
    def _validate_header_hierarchy(self, header_sequence):
        """Validate that headers follow logical hierarchy"""
        if not header_sequence:
            return True
        
        current_level = 0
        for header in header_sequence:
            level = header['level']
            
            # First header can be any level
            if current_level == 0:
                current_level = level
                continue
            
            # Next header can be same level, one level deeper, or any level higher
            if level > current_level + 1:
                return False  # Skipped a level
            
            current_level = level
        
        return True


class ReadabilityAnalyzer:
    """Multi-algorithm readability assessment for AI consumption"""
    
    def calculate_readability_scores(self, text: str):
        """Calculate multiple readability metrics"""
        if not text or len(text.strip()) < 10:
            return {}
        
        try:
            return {
                'flesch_kincaid_grade': round(textstat.flesch_kincaid().grade_score(text), 1),
                'flesch_reading_ease': round(textstat.flesch_reading_ease(text), 1),
                'gunning_fog_index': round(textstat.gunning_fog(text), 1),
                'smog_index': round(textstat.smog_index(text), 1),
                'automated_readability_index': round(textstat.automated_readability_index(text), 1),
                'average_sentence_length': round(textstat.avg_sentence_length(text), 1),
                'average_letter_per_word': round(textstat.avg_letter_per_word(text), 1),
                'reading_difficulty': self._interpret_reading_difficulty(textstat.flesch_kincaid().grade_score(text))
            }
        except Exception as e:
            logger.warning(f"Error calculating readability scores: {str(e)}")
            return {}
    
    def _interpret_reading_difficulty(self, grade_level):
        """Interpret grade level into difficulty category"""
        if grade_level <= 6:
            return "very_easy"
        elif grade_level <= 9:
            return "easy"
        elif grade_level <= 12:
            return "moderate"
        elif grade_level <= 16:
            return "difficult"
        else:
            return "very_difficult"


class AIOptimizationAnalyzer:
    """Evaluate content for AI crawler and featured snippet optimization"""
    
    def analyze_ai_optimization(self, content, content_elements, options):
        """Comprehensive AI optimization analysis"""
        soup = content.soup
        text = content.text_content
        
        # Analyze featured snippet potential
        snippet_potential = self._analyze_featured_snippet_potential(soup, text)
        
        # Count question-answer patterns
        qa_patterns = self._count_question_answer_patterns(text)
        
        # Calculate short paragraph ratio
        paragraph_lengths = content_elements.get('paragraph_lengths', [])
        short_paragraphs = sum(1 for length in paragraph_lengths if length <= 150)
        short_paragraph_ratio = short_paragraphs / len(paragraph_lengths) if paragraph_lengths else 0
        
        # Analyze list usage for AI consumption
        list_usage_score = self._analyze_list_usage(soup, content_elements)
        
        return {
            'featured_snippet_potential': snippet_potential,
            'question_answer_patterns': qa_patterns,
            'short_paragraph_ratio': round(short_paragraph_ratio, 2),
            'list_usage_score': list_usage_score,
            'ai_friendly_formatting': self._assess_ai_friendly_formatting(soup)
        }
    
    def _analyze_featured_snippet_potential(self, soup, text):
        """Analyze potential for featured snippets"""
        score = 0
        
        # Look for definition patterns
        if re.search(r'\b(is|are|means|refers to|defined as)\b', text, re.IGNORECASE):
            score += 2
        
        # Look for numbered lists
        if soup.find_all('ol'):
            score += 2
        
        # Look for bullet points
        if soup.find_all('ul'):
            score += 1
        
        # Look for tables
        if soup.find_all('table'):
            score += 2
        
        # Look for FAQ patterns
        if re.search(r'\b(what|how|why|when|where|who)\b.*\?', text, re.IGNORECASE):
            score += 1
        
        if score >= 5:
            return "high"
        elif score >= 3:
            return "medium"
        else:
            return "low"
    
    def _count_question_answer_patterns(self, text):
        """Count question-answer patterns in content"""
        # Simple pattern matching for questions followed by answers
        questions = re.findall(r'\b(what|how|why|when|where|who)\b[^?]*\?', text, re.IGNORECASE)
        return len(questions)
    
    def _analyze_list_usage(self, soup, content_elements):
        """Analyze list usage for AI optimization"""
        total_lists = content_elements.get('list_count', 0)
        
        if total_lists == 0:
            return 0
        
        # Bonus for numbered lists (better for snippets)
        ol_count = len(soup.find_all('ol'))
        ul_count = len(soup.find_all('ul'))
        
        score = (ol_count * 15) + (ul_count * 10)  # Numbered lists worth more
        return min(100, score)
    
    def _assess_ai_friendly_formatting(self, soup):
        """Assess general AI-friendly formatting"""
        score = 50  # Base score
        
        # Bonus for semantic HTML
        if soup.find_all(['article', 'section', 'main']):
            score += 10
        
        # Bonus for definition lists
        if soup.find_all('dl'):
            score += 5
        
        # Bonus for blockquotes
        if soup.find_all('blockquote'):
            score += 5
        
        return min(100, score)


class SchemaValidator:
    """Validate and analyze structured data markup"""
    
    def detect_and_validate_schema(self, content):
        """Detect and validate schema.org structured data"""
        soup = content.soup
        
        schema_data = {
            'json_ld_schemas': [],
            'microdata_schemas': [],
            'article_schema': False,
            'breadcrumb_schema': False,
            'faq_schema': False,
            'howto_schema': False,
            'organization_schema': False
        }
        
        # Look for JSON-LD scripts
        json_ld_scripts = soup.find_all('script', type='application/ld+json')
        for script in json_ld_scripts:
            try:
                import json
                schema_json = json.loads(script.string)
                schema_type = schema_json.get('@type', 'Unknown')
                schema_data['json_ld_schemas'].append(schema_type)
                
                # Check for specific schema types
                if schema_type in ['Article', 'BlogPosting', 'NewsArticle']:
                    schema_data['article_schema'] = True
                elif schema_type == 'BreadcrumbList':
                    schema_data['breadcrumb_schema'] = True
                elif schema_type == 'FAQPage':
                    schema_data['faq_schema'] = True
                elif schema_type == 'HowTo':
                    schema_data['howto_schema'] = True
                elif schema_type in ['Organization', 'LocalBusiness']:
                    schema_data['organization_schema'] = True
                    
            except (json.JSONDecodeError, AttributeError):
                continue
        
        # Look for microdata
        microdata_elements = soup.find_all(attrs={'itemtype': True})
        for element in microdata_elements:
            item_type = element.get('itemtype', '')
            if 'schema.org' in item_type:
                schema_type = item_type.split('/')[-1]
                schema_data['microdata_schemas'].append(schema_type)
        
        return schema_data


class ParsedContent:
    """Container for parsed HTML content"""
    
    def __init__(self, soup, text_content, html):
        self.soup = soup
        self.text_content = text_content
        self.html = html
```

---

## ðŸ§ª Testing Strategy

### **Unit Tests**
```python
import pytest
from unittest.mock import Mock, AsyncMock
import asyncio

class TestAIContentStructureAnalyzer:
    
    @pytest.fixture
    def analyzer_service(self):
        db_session = Mock()
        cache_service = AsyncMock()
        websocket_service = AsyncMock()
        
        return AIContentStructureAnalyzerService(
            db_session=db_session,
            cache_service=cache_service,
            websocket_service=websocket_service
        )
    
    @pytest.mark.asyncio
    async def test_analyze_content_structure_with_content(self, analyzer_service):
        """Test structure analysis with direct content input"""
        html_content = """
        <html>
            <body>
                <h1>Main Title</h1>
                <p>This is a test paragraph with moderate length.</p>
                <h2>Section Title</h2>
                <ul>
                    <li>Item 1</li>
                    <li>Item 2</li>
                </ul>
            </body>
        </html>
        """
        
        # Mock cache miss
        analyzer_service.cache_service.get.return_value = None
        
        result = await analyzer_service.analyze_content_structure(
            content=html_content,
            user_id="test_user_123"
        )
        
        assert result['overall_score'] > 0
        assert 'analysis_id' in result
        assert result['scores']['header_score'] > 80  # Good header structure
        assert result['analysis']['header_analysis']['h1_count'] == 1
        assert len(result['recommendations']) > 0
    
    @pytest.mark.asyncio
    async def test_header_analysis(self, analyzer_service):
        """Test header hierarchy analysis"""
        html_with_bad_hierarchy = """
        <h1>Title</h1>
        <h3>Skipped H2</h3>
        <h2>Wrong Order</h2>
        """
        
        parsed = analyzer_service.html_parser.parse_content(html_with_bad_hierarchy)
        header_analysis = analyzer_service.html_parser.analyze_header_hierarchy(parsed)
        
        assert not header_analysis['hierarchy_valid']
        assert header_analysis['h1_count'] == 1
    
    @pytest.mark.asyncio
    async def test_readability_scoring(self, analyzer_service):
        """Test readability analysis"""
        simple_text = "This is simple text. Easy to read. Short sentences work well."
        complex_text = "Notwithstanding the aforementioned considerations regarding the multifaceted nature of contemporary discourse analysis paradigms, one must necessarily acknowledge the inherent complexities."
        
        simple_scores = analyzer_service.readability_analyzer.calculate_readability_scores(simple_text)
        complex_scores = analyzer_service.readability_analyzer.calculate_readability_scores(complex_text)
        
        assert simple_scores['flesch_kincaid_grade'] < complex_scores['flesch_kincaid_grade']
        assert simple_scores['reading_difficulty'] in ['very_easy', 'easy']
    
    def test_recommendation_generation(self, analyzer_service):
        """Test recommendation generation logic"""
        analysis_data = {
            'header_analysis': {'h1_count': 0, 'hierarchy_valid': False},
            'readability_metrics': {'flesch_kincaid_grade': 15},
            'ai_analysis': {'question_answer_patterns': 0},
            'overall_score': 45
        }
        
        recommendations = analyzer_service._generate_recommendations(analysis_data)
        
        assert len(recommendations) > 0
        assert any(rec['category'] == 'header_structure' for rec in recommendations)
        assert any(rec['priority'] == 'high' for rec in recommendations)


# Integration Tests
class TestStructureAnalysisIntegration:
    
    @pytest.mark.asyncio
    async def test_full_analysis_workflow(self):
        """Test complete analysis workflow with database storage"""
        # This would require a test database and full service setup
        pass
    
    @pytest.mark.asyncio  
    async def test_url_fetching_and_analysis(self):
        """Test URL fetching and subsequent analysis"""
        # Mock HTTP requests and test URL analysis
        pass
```

### **API Tests**
```python
class TestStructureAnalysisAPI:
    
    def test_post_structure_analysis(self, client, auth_headers):
        """Test POST /api/content/structure-analysis"""
        data = {
            'content': '<h1>Test</h1><p>Test content</p>',
            'options': {
                'analysis_depth': 'standard'
            }
        }
        
        response = client.post(
            '/api/content/structure-analysis',
            json=data,
            headers=auth_headers
        )
        
        assert response.status_code == 200
        assert 'analysis_id' in response.json
        assert 'overall_score' in response.json
    
    def test_get_analysis_results(self, client, auth_headers):
        """Test GET /api/content/structure-analysis/{id}"""
        # Create analysis first, then retrieve
        pass
    
    def test_analysis_validation_errors(self, client, auth_headers):
        """Test validation error handling"""
        # Test with invalid input
        response = client.post(
            '/api/content/structure-analysis',
            json={},
            headers=auth_headers
        )
        
        assert response.status_code == 400
```

---

## ðŸš€ Deployment Configuration

### **Environment Variables**
```bash
# Content Analysis Configuration
STRUCTURE_ANALYSIS_MAX_CONTENT_LENGTH=500000
STRUCTURE_ANALYSIS_TIMEOUT=30
STRUCTURE_ANALYSIS_CACHE_TTL=86400

# External Service Configuration
USER_AGENT="SERPStrategists Structure Analyzer 1.0"
REQUEST_TIMEOUT=10
MAX_REDIRECTS=3

# Performance Configuration
CONCURRENT_ANALYSIS_LIMIT=10
ANALYSIS_QUEUE_SIZE=100
```

### **Dependencies**
```txt
# Core dependencies
beautifulsoup4>=4.12.0
textstat>=0.7.3
aiohttp>=3.8.0
lxml>=4.9.0

# Optional enhancements
readability>=0.3.1
newspaper3k>=0.2.8  # For article extraction
requests-html>=0.10.0  # For JavaScript rendering
```

---

## ðŸ“Š Performance Metrics

### **Response Time Targets**
- **Simple Analysis**: <5 seconds (HTML parsing + basic metrics)
- **Standard Analysis**: <15 seconds (Full analysis with recommendations)
- **Deep Analysis**: <30 seconds (Comprehensive evaluation with schema validation)
- **URL Fetching**: <10 seconds (External content retrieval)

### **Throughput Targets**
- **Concurrent Analyses**: 10 simultaneous analyses
- **Daily Capacity**: 50,000+ analyses per day
- **Cache Hit Rate**: >80% for repeated content
- **Error Rate**: <1% for valid inputs

### **Resource Usage**
- **Memory per Analysis**: <100MB
- **CPU Usage**: <30% for standard analysis
- **Storage per Analysis**: ~50KB database storage

---

## ðŸ” Security Considerations

### **Input Validation**
- **Content Size Limits**: 500KB maximum HTML content
- **URL Validation**: Prevent SSRF attacks through URL whitelisting
- **HTML Sanitization**: Safe parsing without executing JavaScript
- **Rate Limiting**: Per-user analysis limits to prevent abuse

### **Data Privacy**
- **Content Hashing**: Store content fingerprints, not actual content
- **User Isolation**: Strict user-based data access controls
- **Data Retention**: Configurable retention periods for analysis results
- **GDPR Compliance**: Full data export and deletion capabilities

---

## ðŸ’° Cost Analysis

### **Development Effort**
- **Backend Development**: 60-80 hours
- **Database Design & Migration**: 10-15 hours  
- **API Implementation**: 15-20 hours
- **Testing & QA**: 25-30 hours
- **Documentation**: 10-15 hours
- **Total Estimated Effort**: 120-160 hours

### **Operational Costs**
- **Computing Resources**: ~$200/month for moderate usage
- **Database Storage**: ~$50/month for analysis storage
- **External Dependencies**: Minimal (open source libraries)
- **Total Monthly Operational**: ~$250/month

---

## ðŸŽ¯ Success Metrics

### **Technical KPIs**
- **Analysis Accuracy**: >92% user satisfaction with recommendations
- **Performance**: 95th percentile response time <20 seconds
- **Reliability**: 99.5% success rate for valid inputs
- **Cache Efficiency**: >80% cache hit rate

### **Business KPIs**
- **Feature Adoption**: >40% of active users try structure analysis
- **User Engagement**: >70% of users act on recommendations
- **Content Quality**: Measurable improvement in analyzed content
- **Customer Satisfaction**: >85% positive feedback on feature

---

## ðŸš€ Implementation Roadmap

### **Week 1-2: Core Development**
- Implement HTML parsing and structure analysis
- Build readability calculation engines
- Create database models and migrations
- Develop basic scoring algorithms

### **Week 3: AI Optimization Features**
- Implement featured snippet analysis
- Build question-answer pattern detection
- Create schema validation functionality
- Develop recommendation engine

### **Week 4: Integration & Testing**
- API endpoint implementation
- WebSocket progress integration
- Comprehensive testing suite
- Performance optimization

### **Week 5: Deployment & Launch**
- Production deployment
- Monitoring and alerting setup
- Documentation completion
- User acceptance testing

---

## ðŸ“‹ Conclusion

The AI-Ready Content Structure Analyzer represents a significant advancement in content optimization technology, providing users with sophisticated analysis capabilities that directly address the evolving needs of AI-driven search algorithms. With comprehensive scoring, actionable recommendations, and seamless integration into the existing SERPStrategists platform, this feature positions the platform as a leader in AI-first SEO optimization.

**Key Implementation Benefits:**
- **Differentiation**: First-to-market AI content structure analysis
- **User Value**: Actionable insights for content optimization
- **Technical Excellence**: Professional-grade implementation with robust architecture
- **Scalability**: Designed to handle enterprise-level usage
- **Integration**: Seamless integration with existing platform capabilities

**Next Steps**: Proceed with implementation following the outlined technical specification and development roadmap.

---

*This technical specification provides the complete blueprint for implementing Feature 3: AI-Ready Content Structure Analyzer as part of the SERPStrategists AI-first platform enhancement initiative.*